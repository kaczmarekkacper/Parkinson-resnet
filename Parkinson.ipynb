{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Kaczmarek Kacper\n",
    "Jakiś wstęp potem\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "---\n",
    "# Procesowanie sygnału\n",
    "#### 1. Zaciągnięcie danych z bazy https://physionet.org/content/gaitpdb/1.0.0/\n",
    "#### 2. Zaczytanie danych\n",
    "#### 3. Przedstawienie danych\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Zaczytanie danych"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### Zaczytanie metadanych"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kacperk\\AppData\\Local\\Temp\\ipykernel_5252\\2100386468.py:2: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  patients = pd.read_csv('Data/demographics.txt', sep='\\\\t')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "patients = pd.read_csv('Data/demographics.txt', sep='\\\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### Zaczytanie danych o pacjentach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import utils\n",
    "\n",
    "records = utils.readData()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Prezentacja danych"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### Przykład zdrowego i chorego i rozkład sił na lewej i prawej stopie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import utils\n",
    "\n",
    "healthy_patient_id = \"GaCo16\"\n",
    "parkinson_patient_id = \"GaPt26\"\n",
    "sample_number = 240\n",
    "\n",
    "healthy_record = records[healthy_patient_id][\"data1\"]\n",
    "parkinson_record = records[parkinson_patient_id][\"data1\"]\n",
    "\n",
    "utils.createComparisonPlot(healthy_record, parkinson_record, sample_number)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### Każdy czujnik dla zdrowego i chorego"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import utils\n",
    "healthy_patient_id = \"GaCo16\"\n",
    "\n",
    "healthy_record = records[healthy_patient_id][\"data1\"]\n",
    "\n",
    "utils.createAllSensorPlot(healthy_record, 'healthy_all_sensors', sample_number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import utils\n",
    "parkinson_patient_id = \"GaPt26\"\n",
    "\n",
    "parkinson_record = records[parkinson_patient_id][\"data1\"]\n",
    "\n",
    "utils.createAllSensorPlot(parkinson_record, 'parkinson_all_sensors', sample_number)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### Wyliczenie najmniejszej porcji danych chodu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4034\n"
     ]
    }
   ],
   "source": [
    "sample_len = float(\"inf\")\n",
    "for key, value in records.items():\n",
    "    record = value['data1']\n",
    "    sample_len = min(len(record.Time), sample_len)\n",
    "\n",
    "print(sample_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pokazanie zachowań kroków na podstawie czujnika prawej stopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kacperk\\AppData\\Local\\Temp\\ipykernel_5252\\2021356608.py:21: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n",
      "C:\\Users\\kacperk\\AppData\\Local\\Temp\\ipykernel_5252\\2021356608.py:26: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n"
     ]
    }
   ],
   "source": [
    "steps = {}\n",
    "minVal = 30\n",
    "for key, value in records.items():\n",
    "    record = value['data1']\n",
    "    idx = record.index[record.Force_Right < minVal].tolist()[0] + 1\n",
    "    start = record[idx:].index[record.Force_Right[idx:] > minVal].tolist()[0]\n",
    "    end = record[start:].index[record[start:].Force_Right < minVal].tolist()[0]\n",
    "    step = record.Force_Right[start:end+1].tolist()\n",
    "    steps[key] = [x / max(step) for x in step]\n",
    "\n",
    "parkinsons = []\n",
    "healthys = []\n",
    "for key in steps:\n",
    "    hoehnYahr = patients[patients['ID'] == key]['HoehnYahr'].values[0]\n",
    "    parkinsons.append(key) if hoehnYahr > 0 else healthys.append(key)\n",
    "    \n",
    "\n",
    "plt.figure()\n",
    "for key in parkinsons:\n",
    "    plt.plot(steps[key])\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "for key in healthys:\n",
    "    plt.plot(steps[key])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "152\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kacperk\\AppData\\Local\\Temp\\ipykernel_5252\\3348576096.py:27: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n",
      "C:\\Users\\kacperk\\AppData\\Local\\Temp\\ipykernel_5252\\3348576096.py:32: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "steps = {}\n",
    "minVal = 50\n",
    "maxStep = float(\"-inf\")\n",
    "for key, value in records.items():\n",
    "    record = value['data1']\n",
    "    idx = record.index[record.Force_Right < minVal].tolist()[0] + 1\n",
    "    start = record[idx:].index[record.Force_Right[idx:] > minVal].tolist()[0]\n",
    "    end = record[start:].index[record[start:].Force_Right < minVal].tolist()[0]\n",
    "    step = record.Force_Right[start:end+1].tolist()\n",
    "    maxStep = max(maxStep, len(step))\n",
    "    steps[key] = [x / max(step) for x in step]\n",
    "print(maxStep)\n",
    "def rescale(arr, maxStep):\n",
    "    n = len(arr)\n",
    "    return np.interp(np.linspace(0, n, maxStep), np.arange(n), arr)\n",
    "parkinsons = []\n",
    "healthys = []\n",
    "for key in steps:\n",
    "    hoehnYahr = patients[patients['ID'] == key]['HoehnYahr'].values[0]\n",
    "    parkinsons.append(key) if hoehnYahr > 0 else healthys.append(key)\n",
    "    \n",
    "\n",
    "plt.figure()\n",
    "for key in parkinsons:\n",
    "    plt.plot(rescale(steps[key], maxStep))\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "for key in healthys:\n",
    "    plt.plot(rescale(steps[key], maxStep))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Porównanie podczas liczenia do 7 w dół"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kacperk\\AppData\\Local\\Temp\\ipykernel_5252\\4135272709.py:28: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kacperk\\AppData\\Local\\Temp\\ipykernel_5252\\4135272709.py:33: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "steps = {}\n",
    "minVal = 50\n",
    "maxStep = float(\"-inf\")\n",
    "for key, value in records.items():\n",
    "    if key.startswith('Ga') and 'data10' in value.keys():\n",
    "        record = value['data10']\n",
    "        idx = record.index[record.Force_Right < minVal].tolist()[0] + 1\n",
    "        start = record[idx:].index[record.Force_Right[idx:] > minVal].tolist()[0]\n",
    "        end = record[start:].index[record[start:].Force_Right < minVal].tolist()[0]\n",
    "        step = record.Force_Right[start:end+1].tolist()\n",
    "        maxStep = max(maxStep, len(step))\n",
    "        steps[key] = [x / max(step) for x in step]\n",
    "print(maxStep)\n",
    "def rescale(arr, maxStep):\n",
    "    n = len(arr)\n",
    "    return np.interp(np.linspace(0, n, maxStep), np.arange(n), arr)\n",
    "parkinsons = []\n",
    "healthys = []\n",
    "for key in steps:\n",
    "    hoehnYahr = patients[patients['ID'] == key]['HoehnYahr'].values[0]\n",
    "    parkinsons.append(key) if hoehnYahr > 0 else healthys.append(key)\n",
    "    \n",
    "\n",
    "plt.figure()\n",
    "for key in parkinsons:\n",
    "    plt.plot(rescale(steps[key], maxStep))\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "for key in healthys:\n",
    "    plt.plot(rescale(steps[key], maxStep))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### Prezentacja typów falek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python38\\lib\\site-packages\\matplotlib\\cbook\\__init__.py:1369: ComplexWarning: Casting complex values to real discards the imaginary part\n",
      "  return np.asarray(x, float)\n"
     ]
    }
   ],
   "source": [
    "from scipy import signal\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "points = 100\n",
    "a = 4\n",
    "w = 0\n",
    "\n",
    "plt.figure()\n",
    "vec_ricker = signal.ricker(points, a)\n",
    "plt.plot(vec_ricker)\n",
    "\n",
    "plt.savefig(\"plots/wavelet-type-ricker.pdf\", format=\"pdf\", bbox_inches=\"tight\")\n",
    "\n",
    "plt.figure()\n",
    "vec_morlet2 = signal.morlet2(points, a, w)\n",
    "plt.plot(vec_morlet2)\n",
    "\n",
    "plt.savefig(\"plots/wavelet-type-morlet.pdf\", format=\"pdf\", bbox_inches=\"tight\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### Wykresy transfomaty falkowej"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_number = 1000\n",
    "widths = np.arange(1, 100)\n",
    "w = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from scipy import signal\n",
    "import numpy as np\n",
    "\n",
    "healthy_patient_id = \"GaCo16\"\n",
    "parkinson_patient_id = \"GaPt26\"\n",
    "\n",
    "healthy_record = records[healthy_patient_id][\"data1\"]\n",
    "parkinson_record = records[parkinson_patient_id][\"data1\"]\n",
    "\n",
    "y_healthy = healthy_record.Force_Left.head(sample_number) - healthy_record.Force_Right.head(sample_number)\n",
    "y_healthy = y_healthy.abs()\n",
    "x_healthy = healthy_record.Time.head(sample_number)\n",
    "\n",
    "y_parkinson = parkinson_record.Force_Left.head(sample_number) - parkinson_record.Force_Right.head(sample_number)\n",
    "y_parkinson = y_parkinson.abs()\n",
    "x_parkinson = parkinson_record.Time.head(sample_number)\n",
    "\n",
    "cwtFunc = lambda: signal.cwt(y_healthy, signal.ricker, widths, dtype='float64')\n",
    "path = \"plots/healthy-wavelet\"\n",
    "utils.createWaveletPlot(x_healthy, cwtFunc, width, path, 'pdf')\n",
    "\n",
    "cwtFunc = lambda: signal.cwt(y_parkinson, signal.ricker, widths, dtype='float64')\n",
    "path = \"plots/parkinson-wavelet\"\n",
    "utils.createWaveletPlot(x_parkinson, cwtFunc, width, path, 'pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Porównanie tranformaty falkowej morleta i rickera"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python38\\lib\\site-packages\\scipy\\signal\\_wavelets.py:470: ComplexWarning: Casting complex values to real discards the imaginary part\n",
      "  output[ind] = convolve(data, wavelet_data, mode='same')\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from scipy import signal\n",
    "import numpy as np\n",
    "\n",
    "healthy_patient_id = \"GaCo16\"\n",
    "parkinson_patient_id = \"GaPt26\"\n",
    "\n",
    "healthy_record = records[healthy_patient_id][\"data1\"]\n",
    "\n",
    "y_healthy = healthy_record.Force_Left.head(sample_number)\n",
    "x_healthy = healthy_record.Time.head(sample_number)\n",
    "\n",
    "\n",
    "cwtFunc = lambda: signal.cwt(y_healthy, signal.morlet2, widths, dtype='float64', w=w)\n",
    "path = \"plots/healthy-morlet\"\n",
    "utils.createWaveletPlot(x_healthy, cwtFunc, width, path, 'pdf')\n",
    "\n",
    "cwtFunc = lambda: signal.cwt(y_healthy, signal.ricker, widths, dtype='float64')\n",
    "path = \"plots/healthy-ricker\"\n",
    "utils.createWaveletPlot(x_healthy, cwtFunc, width, path, 'pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Klasyfikacja"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 250"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scenariusz 1 - Pojedyncze czujniki"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "scenario1 = False\n",
    "if scenario1:\n",
    "    main_path = f'Datasets/Binary/AllSensors'\n",
    "    utils.removeDatasetFolders(main_path)\n",
    "    for wavelet in ['Ricker', 'Morlet']:\n",
    "        utils.createDatasetFolders(f'{main_path}/{wavelet}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "sensors = [\n",
    "    (lambda x: x.L1, \"L1\"),\n",
    "    (lambda x: x.L2, \"L2\"),\n",
    "    (lambda x: x.L3, \"L3\"),\n",
    "    (lambda x: x.L4, \"L4\"),\n",
    "    (lambda x: x.L5, \"L5\"),\n",
    "    (lambda x: x.L6, \"L6\"),\n",
    "    (lambda x: x.L7, \"L7\"),\n",
    "    (lambda x: x.L8, \"L8\"),\n",
    "    (lambda x: x.R1, \"R1\"),\n",
    "    (lambda x: x.R2, \"R2\"),\n",
    "    (lambda x: x.R3, \"R3\"),\n",
    "    (lambda x: x.R4, \"R4\"),\n",
    "    (lambda x: x.R5, \"R5\"),\n",
    "    (lambda x: x.R6, \"R6\"),\n",
    "    (lambda x: x.R7, \"R7\"),\n",
    "    (lambda x: x.R8, \"R8\"),\n",
    "    ]\n",
    "\n",
    "i = 1\n",
    "if scenario1:\n",
    "    for id, value in records.items():\n",
    "        print(f'{i}/{len(records)}: Processing ID = {id}')\n",
    "        i = i + 1\n",
    "        parkinson = utils.getParkinsonStatus(patients, id)\n",
    "        hoehnYahr = utils.getHoehnYahrStatus(patients, id)\n",
    "        record = value['data1']\n",
    "\n",
    "        splits_list = [i for i in range(0, len(record), sample_number)]\n",
    "        \n",
    "        utils.createDatabase(record, id, sensors, splits_list, sample_number, main_path, parkinson, widths, w)\n",
    "    print('-----------------END-----------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if scenario1:\n",
    "    for wavelet in ['Ricker', 'Morlet']:\n",
    "        utils.createDatasets(f'{main_path}/{wavelet}')\n",
    "    print('Datasets created')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### Uczenie sieci"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import LearningUtils\n",
    "import importlib\n",
    "import ModelTrainer\n",
    "from torchvision import models\n",
    "import logging\n",
    "import sys\n",
    "importlib.reload(ModelTrainer)\n",
    "importlib.reload(LearningUtils)\n",
    "\n",
    "\n",
    "if False:\n",
    "    for wavelet in ['Ricker', 'Morlet']:\n",
    "        print(f'Resnet for {wavelet}')\n",
    "        imgdir = f\"{main_path}/{wavelet}\"\n",
    "        # logger\n",
    "        logger = logging.getLogger()\n",
    "        logger.setLevel(logging.DEBUG)\n",
    "        fhandler = logging.FileHandler(f'{imgdir}/log.txt', mode='w')\n",
    "        consoleHandler = logging.StreamHandler(sys.stdout)\n",
    "        logger.addHandler(fhandler)\n",
    "        logger.addHandler(consoleHandler)\n",
    "\n",
    "        classes = LearningUtils.get_classes(imgdir)\n",
    "        train_data_loader, validation_data_loader, test_data_loader = LearningUtils.prepare_data(imgdir, 128)\n",
    "        model_trainer = ModelTrainer.ModelTrainer(classes, imgdir)\n",
    "        resnet = models.resnet18(weights=models.ResNet18_Weights.DEFAULT)\n",
    "        model = model_trainer.train_resnet(resnet, train_data_loader, validation_data_loader, num_epochs=num_epochs)\n",
    "        model.eval()\n",
    "        LearningUtils.predict_image(model, test_data_loader, classes)\n",
    "\n",
    "        logger.removeHandler(fhandler)\n",
    "        logger.removeHandler(consoleHandler)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Scenariusz 2 - Tylko sumaryczne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "scenario2 = True\n",
    "if scenario2:\n",
    "    main_path = f'Datasets/Binary/OnlySums'\n",
    "    utils.removeDatasetFolders(main_path)\n",
    "    for wavelet in ['Ricker', 'Morlet']:\n",
    "        utils.createDatasetFolders(f'{main_path}/{wavelet}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/165: Processing ID = JuPt03\n",
      "2/165: Processing ID = GaPt15\n",
      "3/165: Processing ID = GaCo08\n",
      "4/165: Processing ID = GaPt14\n",
      "5/165: Processing ID = JuPt01\n",
      "6/165: Processing ID = JuPt28\n",
      "7/165: Processing ID = JuCo06\n",
      "8/165: Processing ID = GaPt24\n",
      "9/165: Processing ID = SiCo22\n",
      "10/165: Processing ID = JuPt29\n",
      "11/165: Processing ID = SiCo16\n",
      "12/165: Processing ID = JuCo19\n",
      "13/165: Processing ID = GaPt28\n",
      "14/165: Processing ID = JuPt24\n",
      "15/165: Processing ID = SiCo11\n",
      "16/165: Processing ID = GaPt08\n",
      "17/165: Processing ID = GaPt20\n",
      "18/165: Processing ID = GaCo09\n",
      "19/165: Processing ID = GaPt26\n",
      "20/165: Processing ID = SiPt29\n",
      "21/165: Processing ID = SiCo01\n",
      "22/165: Processing ID = SiPt14\n",
      "23/165: Processing ID = SiPt18\n",
      "24/165: Processing ID = SiCo28\n",
      "25/165: Processing ID = SiPt20\n",
      "26/165: Processing ID = JuPt06\n",
      "27/165: Processing ID = JuCo04\n",
      "28/165: Processing ID = GaPt31\n",
      "29/165: Processing ID = SiPt38\n",
      "30/165: Processing ID = JuCo24\n",
      "31/165: Processing ID = GaPt19\n",
      "32/165: Processing ID = JuPt20\n",
      "33/165: Processing ID = GaCo13\n",
      "34/165: Processing ID = SiCo03\n",
      "35/165: Processing ID = JuPt23\n",
      "36/165: Processing ID = SiCo24\n",
      "37/165: Processing ID = SiCo04\n",
      "38/165: Processing ID = JuPt04\n",
      "39/165: Processing ID = GaPt09\n",
      "40/165: Processing ID = JuPt09\n",
      "41/165: Processing ID = JuPt15\n",
      "42/165: Processing ID = GaCo01\n",
      "43/165: Processing ID = JuPt17\n",
      "44/165: Processing ID = GaPt23\n",
      "45/165: Processing ID = GaPt32\n",
      "46/165: Processing ID = SiCo23\n",
      "47/165: Processing ID = JuPt11\n",
      "48/165: Processing ID = GaPt29\n",
      "49/165: Processing ID = JuPt21\n",
      "50/165: Processing ID = GaCo15\n",
      "51/165: Processing ID = GaCo06\n",
      "52/165: Processing ID = SiPt17\n",
      "53/165: Processing ID = GaCo17\n",
      "54/165: Processing ID = JuPt05\n",
      "55/165: Processing ID = JuCo18\n",
      "56/165: Processing ID = JuCo21\n",
      "57/165: Processing ID = SiPt37\n",
      "58/165: Processing ID = GaCo10\n",
      "59/165: Processing ID = GaCo02\n",
      "60/165: Processing ID = JuPt10\n",
      "61/165: Processing ID = JuPt26\n",
      "62/165: Processing ID = SiPt39\n",
      "63/165: Processing ID = SiPt13\n",
      "64/165: Processing ID = SiCo08\n",
      "65/165: Processing ID = GaPt27\n",
      "66/165: Processing ID = JuPt14\n",
      "67/165: Processing ID = GaCo22\n",
      "68/165: Processing ID = SiCo27\n",
      "69/165: Processing ID = GaPt13\n",
      "70/165: Processing ID = JuCo09\n",
      "71/165: Processing ID = JuCo03\n",
      "72/165: Processing ID = JuCo16\n",
      "73/165: Processing ID = SiCo07\n",
      "74/165: Processing ID = GaPt22\n",
      "75/165: Processing ID = GaPt18\n",
      "76/165: Processing ID = SiPt34\n",
      "77/165: Processing ID = JuPt08\n",
      "78/165: Processing ID = JuCo15\n",
      "79/165: Processing ID = JuCo13\n",
      "80/165: Processing ID = SiCo10\n",
      "81/165: Processing ID = JuCo02\n",
      "82/165: Processing ID = JuCo23\n",
      "83/165: Processing ID = GaPt12\n",
      "84/165: Processing ID = SiCo30\n",
      "85/165: Processing ID = JuCo20\n",
      "86/165: Processing ID = GaCo11\n",
      "87/165: Processing ID = GaPt16\n",
      "88/165: Processing ID = SiCo21\n",
      "89/165: Processing ID = GaCo05\n",
      "90/165: Processing ID = SiCo13\n",
      "91/165: Processing ID = JuCo22\n",
      "92/165: Processing ID = SiCo19\n",
      "93/165: Processing ID = SiCo09\n",
      "94/165: Processing ID = GaPt21\n",
      "95/165: Processing ID = JuCo08\n",
      "96/165: Processing ID = JuPt22\n",
      "97/165: Processing ID = GaPt33\n",
      "98/165: Processing ID = GaCo04\n",
      "99/165: Processing ID = JuPt16\n",
      "100/165: Processing ID = SiPt12\n",
      "101/165: Processing ID = JuPt25\n",
      "102/165: Processing ID = GaPt17\n",
      "103/165: Processing ID = JuCo25\n",
      "104/165: Processing ID = SiPt04\n",
      "105/165: Processing ID = JuPt13\n",
      "106/165: Processing ID = SiCo15\n",
      "107/165: Processing ID = SiPt15\n",
      "108/165: Processing ID = GaPt30\n",
      "109/165: Processing ID = SiCo05\n",
      "110/165: Processing ID = SiCo20\n",
      "111/165: Processing ID = SiPt21\n",
      "112/165: Processing ID = JuPt18\n",
      "113/165: Processing ID = SiPt30\n",
      "114/165: Processing ID = SiCo17\n",
      "115/165: Processing ID = GaCo03\n",
      "116/165: Processing ID = GaPt25\n",
      "117/165: Processing ID = SiCo26\n",
      "118/165: Processing ID = SiPt40\n",
      "119/165: Processing ID = SiPt10\n",
      "120/165: Processing ID = SiCo25\n",
      "121/165: Processing ID = JuCo01\n",
      "122/165: Processing ID = JuPt12\n",
      "123/165: Processing ID = SiPt19\n",
      "124/165: Processing ID = SiPt02\n",
      "125/165: Processing ID = SiPt36\n",
      "126/165: Processing ID = SiPt27\n",
      "127/165: Processing ID = GaCo07\n",
      "128/165: Processing ID = SiPt23\n",
      "129/165: Processing ID = SiPt07\n",
      "130/165: Processing ID = GaPt07\n",
      "131/165: Processing ID = SiPt28\n",
      "132/165: Processing ID = SiPt32\n",
      "133/165: Processing ID = JuPt07\n",
      "134/165: Processing ID = JuPt19\n",
      "135/165: Processing ID = SiPt31\n",
      "136/165: Processing ID = GaPt05\n",
      "137/165: Processing ID = SiPt24\n",
      "138/165: Processing ID = GaCo14\n",
      "139/165: Processing ID = SiCo14\n",
      "140/165: Processing ID = JuCo26\n",
      "141/165: Processing ID = SiPt09\n",
      "142/165: Processing ID = SiCo29\n",
      "143/165: Processing ID = JuCo11\n",
      "144/165: Processing ID = JuCo07\n",
      "145/165: Processing ID = SiPt16\n",
      "146/165: Processing ID = SiPt08\n",
      "147/165: Processing ID = GaCo16\n",
      "148/165: Processing ID = SiPt25\n",
      "149/165: Processing ID = JuCo17\n",
      "150/165: Processing ID = JuPt02\n",
      "151/165: Processing ID = SiPt22\n",
      "152/165: Processing ID = JuPt27\n",
      "153/165: Processing ID = GaPt04\n",
      "154/165: Processing ID = SiPt35\n",
      "155/165: Processing ID = JuCo12\n",
      "156/165: Processing ID = GaPt03\n",
      "157/165: Processing ID = SiCo12\n",
      "158/165: Processing ID = SiPt05\n",
      "159/165: Processing ID = SiCo06\n",
      "160/165: Processing ID = SiCo18\n",
      "161/165: Processing ID = SiPt33\n",
      "162/165: Processing ID = GaPt06\n",
      "163/165: Processing ID = GaCo12\n",
      "164/165: Processing ID = JuCo14\n",
      "165/165: Processing ID = JuCo05\n",
      "-----------------END-----------------\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "sensors = [\n",
    "    (lambda x: x.Force_Left, \"Force_Left\"),\n",
    "    (lambda x: x.Force_Right, \"Force_Right\")\n",
    "    ]\n",
    "\n",
    "i = 1\n",
    "if scenario2:\n",
    "    for id, value in records.items():\n",
    "        print(f'{i}/{len(records)}: Processing ID = {id}')\n",
    "        i = i + 1\n",
    "        parkinson = utils.getParkinsonStatus(patients, id)\n",
    "        hoehnYahr = utils.getHoehnYahrStatus(patients, id)\n",
    "        record = value['data1']\n",
    "\n",
    "        splits_list = [i for i in range(0, len(record), sample_number)]\n",
    "\n",
    "        utils.createDatabase(record, id, sensors, splits_list, sample_number, main_path, parkinson, widths, w)\n",
    "    print('-----------------END-----------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datasets created\n"
     ]
    }
   ],
   "source": [
    "if scenario2:\n",
    "    for wavelet in ['Ricker', 'Morlet']:\n",
    "        utils.createDatasets(f'{main_path}/{wavelet}')\n",
    "    print('Datasets created')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### Uczenie sieci"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import LearningUtils\n",
    "import importlib\n",
    "import ModelTrainer\n",
    "from torchvision import models\n",
    "import logging\n",
    "import sys\n",
    "importlib.reload(ModelTrainer)\n",
    "importlib.reload(LearningUtils)\n",
    "\n",
    "\n",
    "if False:\n",
    "    for wavelet in ['Ricker', 'Morlet']:\n",
    "        print(f'Resnet for {wavelet}')\n",
    "        imgdir = f\"{main_path}/{wavelet}\"\n",
    "        # logger\n",
    "        logger = logging.getLogger()\n",
    "        logger.setLevel(logging.DEBUG)\n",
    "        fhandler = logging.FileHandler(f'{imgdir}/log.txt', mode='w')\n",
    "        consoleHandler = logging.StreamHandler(sys.stdout)\n",
    "        logger.addHandler(fhandler)\n",
    "        logger.addHandler(consoleHandler)\n",
    "\n",
    "        classes = LearningUtils.get_classes(imgdir)\n",
    "        train_data_loader, validation_data_loader, test_data_loader = LearningUtils.prepare_data(imgdir, 64)\n",
    "        model_trainer = ModelTrainer.ModelTrainer(classes, imgdir)\n",
    "        resnet = models.resnet18(weights=models.ResNet18_Weights.DEFAULT)\n",
    "        model = model_trainer.train_resnet(resnet, train_data_loader, validation_data_loader, num_epochs=num_epochs)\n",
    "        model.eval()\n",
    "        LearningUtils.predict_image(model, test_data_loader, classes)\n",
    "\n",
    "        logger.removeHandler(fhandler)\n",
    "        logger.removeHandler(consoleHandler)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Scenariusz 3 - Tylko różnica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "scenario3 = True\n",
    "if scenario3:\n",
    "    main_path = f'Datasets/Binary/OnlySumsDiff'\n",
    "    utils.removeDatasetFolders(main_path)\n",
    "    for wavelet in ['Ricker', 'Morlet']:\n",
    "        utils.createDatasetFolders(f'{main_path}/{wavelet}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/165: Processing ID = JuPt03\n",
      "2/165: Processing ID = GaPt15\n",
      "3/165: Processing ID = GaCo08\n",
      "4/165: Processing ID = GaPt14\n",
      "5/165: Processing ID = JuPt01\n",
      "6/165: Processing ID = JuPt28\n",
      "7/165: Processing ID = JuCo06\n",
      "8/165: Processing ID = GaPt24\n",
      "9/165: Processing ID = SiCo22\n",
      "10/165: Processing ID = JuPt29\n",
      "11/165: Processing ID = SiCo16\n",
      "12/165: Processing ID = JuCo19\n",
      "13/165: Processing ID = GaPt28\n",
      "14/165: Processing ID = JuPt24\n",
      "15/165: Processing ID = SiCo11\n",
      "16/165: Processing ID = GaPt08\n",
      "17/165: Processing ID = GaPt20\n",
      "18/165: Processing ID = GaCo09\n",
      "19/165: Processing ID = GaPt26\n",
      "20/165: Processing ID = SiPt29\n",
      "21/165: Processing ID = SiCo01\n",
      "22/165: Processing ID = SiPt14\n",
      "23/165: Processing ID = SiPt18\n",
      "24/165: Processing ID = SiCo28\n",
      "25/165: Processing ID = SiPt20\n",
      "26/165: Processing ID = JuPt06\n",
      "27/165: Processing ID = JuCo04\n",
      "28/165: Processing ID = GaPt31\n",
      "29/165: Processing ID = SiPt38\n",
      "30/165: Processing ID = JuCo24\n",
      "31/165: Processing ID = GaPt19\n",
      "32/165: Processing ID = JuPt20\n",
      "33/165: Processing ID = GaCo13\n",
      "34/165: Processing ID = SiCo03\n",
      "35/165: Processing ID = JuPt23\n",
      "36/165: Processing ID = SiCo24\n",
      "37/165: Processing ID = SiCo04\n",
      "38/165: Processing ID = JuPt04\n",
      "39/165: Processing ID = GaPt09\n",
      "40/165: Processing ID = JuPt09\n",
      "41/165: Processing ID = JuPt15\n",
      "42/165: Processing ID = GaCo01\n",
      "43/165: Processing ID = JuPt17\n",
      "44/165: Processing ID = GaPt23\n",
      "45/165: Processing ID = GaPt32\n",
      "46/165: Processing ID = SiCo23\n",
      "47/165: Processing ID = JuPt11\n",
      "48/165: Processing ID = GaPt29\n",
      "49/165: Processing ID = JuPt21\n",
      "50/165: Processing ID = GaCo15\n",
      "51/165: Processing ID = GaCo06\n",
      "52/165: Processing ID = SiPt17\n",
      "53/165: Processing ID = GaCo17\n",
      "54/165: Processing ID = JuPt05\n",
      "55/165: Processing ID = JuCo18\n",
      "56/165: Processing ID = JuCo21\n",
      "57/165: Processing ID = SiPt37\n",
      "58/165: Processing ID = GaCo10\n",
      "59/165: Processing ID = GaCo02\n",
      "60/165: Processing ID = JuPt10\n",
      "61/165: Processing ID = JuPt26\n",
      "62/165: Processing ID = SiPt39\n",
      "63/165: Processing ID = SiPt13\n",
      "64/165: Processing ID = SiCo08\n",
      "65/165: Processing ID = GaPt27\n",
      "66/165: Processing ID = JuPt14\n",
      "67/165: Processing ID = GaCo22\n",
      "68/165: Processing ID = SiCo27\n",
      "69/165: Processing ID = GaPt13\n",
      "70/165: Processing ID = JuCo09\n",
      "71/165: Processing ID = JuCo03\n",
      "72/165: Processing ID = JuCo16\n",
      "73/165: Processing ID = SiCo07\n",
      "74/165: Processing ID = GaPt22\n",
      "75/165: Processing ID = GaPt18\n",
      "76/165: Processing ID = SiPt34\n",
      "77/165: Processing ID = JuPt08\n",
      "78/165: Processing ID = JuCo15\n",
      "79/165: Processing ID = JuCo13\n",
      "80/165: Processing ID = SiCo10\n",
      "81/165: Processing ID = JuCo02\n",
      "82/165: Processing ID = JuCo23\n",
      "83/165: Processing ID = GaPt12\n",
      "84/165: Processing ID = SiCo30\n",
      "85/165: Processing ID = JuCo20\n",
      "86/165: Processing ID = GaCo11\n",
      "87/165: Processing ID = GaPt16\n",
      "88/165: Processing ID = SiCo21\n",
      "89/165: Processing ID = GaCo05\n",
      "90/165: Processing ID = SiCo13\n",
      "91/165: Processing ID = JuCo22\n",
      "92/165: Processing ID = SiCo19\n",
      "93/165: Processing ID = SiCo09\n",
      "94/165: Processing ID = GaPt21\n",
      "95/165: Processing ID = JuCo08\n",
      "96/165: Processing ID = JuPt22\n",
      "97/165: Processing ID = GaPt33\n",
      "98/165: Processing ID = GaCo04\n",
      "99/165: Processing ID = JuPt16\n",
      "100/165: Processing ID = SiPt12\n",
      "101/165: Processing ID = JuPt25\n",
      "102/165: Processing ID = GaPt17\n",
      "103/165: Processing ID = JuCo25\n",
      "104/165: Processing ID = SiPt04\n",
      "105/165: Processing ID = JuPt13\n",
      "106/165: Processing ID = SiCo15\n",
      "107/165: Processing ID = SiPt15\n",
      "108/165: Processing ID = GaPt30\n",
      "109/165: Processing ID = SiCo05\n",
      "110/165: Processing ID = SiCo20\n",
      "111/165: Processing ID = SiPt21\n",
      "112/165: Processing ID = JuPt18\n",
      "113/165: Processing ID = SiPt30\n",
      "114/165: Processing ID = SiCo17\n",
      "115/165: Processing ID = GaCo03\n",
      "116/165: Processing ID = GaPt25\n",
      "117/165: Processing ID = SiCo26\n",
      "118/165: Processing ID = SiPt40\n",
      "119/165: Processing ID = SiPt10\n",
      "120/165: Processing ID = SiCo25\n",
      "121/165: Processing ID = JuCo01\n",
      "122/165: Processing ID = JuPt12\n",
      "123/165: Processing ID = SiPt19\n",
      "124/165: Processing ID = SiPt02\n",
      "125/165: Processing ID = SiPt36\n",
      "126/165: Processing ID = SiPt27\n",
      "127/165: Processing ID = GaCo07\n",
      "128/165: Processing ID = SiPt23\n",
      "129/165: Processing ID = SiPt07\n",
      "130/165: Processing ID = GaPt07\n",
      "131/165: Processing ID = SiPt28\n",
      "132/165: Processing ID = SiPt32\n",
      "133/165: Processing ID = JuPt07\n",
      "134/165: Processing ID = JuPt19\n",
      "135/165: Processing ID = SiPt31\n",
      "136/165: Processing ID = GaPt05\n",
      "137/165: Processing ID = SiPt24\n",
      "138/165: Processing ID = GaCo14\n",
      "139/165: Processing ID = SiCo14\n",
      "140/165: Processing ID = JuCo26\n",
      "141/165: Processing ID = SiPt09\n",
      "142/165: Processing ID = SiCo29\n",
      "143/165: Processing ID = JuCo11\n",
      "144/165: Processing ID = JuCo07\n",
      "145/165: Processing ID = SiPt16\n",
      "146/165: Processing ID = SiPt08\n",
      "147/165: Processing ID = GaCo16\n",
      "148/165: Processing ID = SiPt25\n",
      "149/165: Processing ID = JuCo17\n",
      "150/165: Processing ID = JuPt02\n",
      "151/165: Processing ID = SiPt22\n",
      "152/165: Processing ID = JuPt27\n",
      "153/165: Processing ID = GaPt04\n",
      "154/165: Processing ID = SiPt35\n",
      "155/165: Processing ID = JuCo12\n",
      "156/165: Processing ID = GaPt03\n",
      "157/165: Processing ID = SiCo12\n",
      "158/165: Processing ID = SiPt05\n",
      "159/165: Processing ID = SiCo06\n",
      "160/165: Processing ID = SiCo18\n",
      "161/165: Processing ID = SiPt33\n",
      "162/165: Processing ID = GaPt06\n",
      "163/165: Processing ID = GaCo12\n",
      "164/165: Processing ID = JuCo14\n",
      "165/165: Processing ID = JuCo05\n",
      "-----------------END-----------------\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "sensors = [\n",
    "    (lambda x: x.Force_Left - x.Force_Right, \"OnlySumsDiff\")\n",
    "    ]\n",
    "\n",
    "i = 1\n",
    "if scenario3:\n",
    "    for id, value in records.items():\n",
    "        print(f'{i}/{len(records)}: Processing ID = {id}')\n",
    "        i = i + 1\n",
    "        parkinson = utils.getParkinsonStatus(patients, id)\n",
    "        hoehnYahr = utils.getHoehnYahrStatus(patients, id)\n",
    "        record = value['data1']\n",
    "\n",
    "        splits_list = [i for i in range(0, len(record), sample_number)]\n",
    "\n",
    "        utils.createDatabase(record, id, sensors, splits_list, sample_number, main_path, parkinson, widths, w)\n",
    "    print('-----------------END-----------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datasets created\n"
     ]
    }
   ],
   "source": [
    "if scenario3:\n",
    "    for wavelet in ['Ricker', 'Morlet']:\n",
    "        utils.createDatasets(f'{main_path}/{wavelet}')\n",
    "    print('Datasets created')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### Uczenie sieci"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import LearningUtils\n",
    "import importlib\n",
    "import ModelTrainer\n",
    "from torchvision import models\n",
    "import logging\n",
    "import sys\n",
    "importlib.reload(ModelTrainer)\n",
    "importlib.reload(LearningUtils)\n",
    "\n",
    "\n",
    "if False:\n",
    "    for wavelet in ['Ricker', 'Morlet']:\n",
    "        print(f'Resnet for {wavelet}')\n",
    "        imgdir = f\"{main_path}/{wavelet}\"\n",
    "        # logger\n",
    "        logger = logging.getLogger()\n",
    "        logger.setLevel(logging.DEBUG)\n",
    "        fhandler = logging.FileHandler(f'{imgdir}/log.txt', mode='w')\n",
    "        consoleHandler = logging.StreamHandler(sys.stdout)\n",
    "        logger.addHandler(fhandler)\n",
    "        logger.addHandler(consoleHandler)\n",
    "\n",
    "        classes = LearningUtils.get_classes(imgdir)\n",
    "        train_data_loader, validation_data_loader, test_data_loader = LearningUtils.prepare_data(imgdir, 64)\n",
    "        model_trainer = ModelTrainer.ModelTrainer(classes, imgdir)\n",
    "        resnet = models.resnet18(weights=models.ResNet18_Weights.DEFAULT)\n",
    "        model = model_trainer.train_resnet(resnet, train_data_loader, validation_data_loader, num_epochs=num_epochs)\n",
    "        model.eval()\n",
    "        LearningUtils.predict_image(model, test_data_loader, classes)\n",
    "\n",
    "        logger.removeHandler(fhandler)\n",
    "        logger.removeHandler(consoleHandler)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scenariusz 4 - Różnica pojedynczych"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "scenario4 = True\n",
    "if scenario4:\n",
    "    main_path = f'Datasets/Binary/AllSensorsDiff'\n",
    "    utils.removeDatasetFolders(main_path)\n",
    "    for wavelet in ['Ricker', 'Morlet']:\n",
    "        utils.createDatasetFolders(f'{main_path}/{wavelet}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/165: Processing ID = JuPt03\n",
      "2/165: Processing ID = GaPt15\n",
      "3/165: Processing ID = GaCo08\n",
      "4/165: Processing ID = GaPt14\n",
      "5/165: Processing ID = JuPt01\n",
      "6/165: Processing ID = JuPt28\n",
      "7/165: Processing ID = JuCo06\n",
      "8/165: Processing ID = GaPt24\n",
      "9/165: Processing ID = SiCo22\n",
      "10/165: Processing ID = JuPt29\n",
      "11/165: Processing ID = SiCo16\n",
      "12/165: Processing ID = JuCo19\n",
      "13/165: Processing ID = GaPt28\n",
      "14/165: Processing ID = JuPt24\n",
      "15/165: Processing ID = SiCo11\n",
      "16/165: Processing ID = GaPt08\n",
      "17/165: Processing ID = GaPt20\n",
      "18/165: Processing ID = GaCo09\n",
      "19/165: Processing ID = GaPt26\n",
      "20/165: Processing ID = SiPt29\n",
      "21/165: Processing ID = SiCo01\n",
      "22/165: Processing ID = SiPt14\n",
      "23/165: Processing ID = SiPt18\n",
      "24/165: Processing ID = SiCo28\n",
      "25/165: Processing ID = SiPt20\n",
      "26/165: Processing ID = JuPt06\n",
      "27/165: Processing ID = JuCo04\n",
      "28/165: Processing ID = GaPt31\n",
      "29/165: Processing ID = SiPt38\n",
      "30/165: Processing ID = JuCo24\n",
      "31/165: Processing ID = GaPt19\n",
      "32/165: Processing ID = JuPt20\n",
      "33/165: Processing ID = GaCo13\n",
      "34/165: Processing ID = SiCo03\n",
      "35/165: Processing ID = JuPt23\n",
      "36/165: Processing ID = SiCo24\n",
      "37/165: Processing ID = SiCo04\n",
      "38/165: Processing ID = JuPt04\n",
      "39/165: Processing ID = GaPt09\n",
      "40/165: Processing ID = JuPt09\n",
      "41/165: Processing ID = JuPt15\n",
      "42/165: Processing ID = GaCo01\n",
      "43/165: Processing ID = JuPt17\n",
      "44/165: Processing ID = GaPt23\n",
      "45/165: Processing ID = GaPt32\n",
      "46/165: Processing ID = SiCo23\n",
      "47/165: Processing ID = JuPt11\n",
      "48/165: Processing ID = GaPt29\n",
      "49/165: Processing ID = JuPt21\n",
      "50/165: Processing ID = GaCo15\n",
      "51/165: Processing ID = GaCo06\n",
      "52/165: Processing ID = SiPt17\n",
      "53/165: Processing ID = GaCo17\n",
      "54/165: Processing ID = JuPt05\n",
      "55/165: Processing ID = JuCo18\n",
      "56/165: Processing ID = JuCo21\n",
      "57/165: Processing ID = SiPt37\n",
      "58/165: Processing ID = GaCo10\n",
      "59/165: Processing ID = GaCo02\n",
      "60/165: Processing ID = JuPt10\n",
      "61/165: Processing ID = JuPt26\n",
      "62/165: Processing ID = SiPt39\n",
      "63/165: Processing ID = SiPt13\n",
      "64/165: Processing ID = SiCo08\n",
      "65/165: Processing ID = GaPt27\n",
      "66/165: Processing ID = JuPt14\n",
      "67/165: Processing ID = GaCo22\n",
      "68/165: Processing ID = SiCo27\n",
      "69/165: Processing ID = GaPt13\n",
      "70/165: Processing ID = JuCo09\n",
      "71/165: Processing ID = JuCo03\n",
      "72/165: Processing ID = JuCo16\n",
      "73/165: Processing ID = SiCo07\n",
      "74/165: Processing ID = GaPt22\n",
      "75/165: Processing ID = GaPt18\n",
      "76/165: Processing ID = SiPt34\n",
      "77/165: Processing ID = JuPt08\n",
      "78/165: Processing ID = JuCo15\n",
      "79/165: Processing ID = JuCo13\n",
      "80/165: Processing ID = SiCo10\n",
      "81/165: Processing ID = JuCo02\n",
      "82/165: Processing ID = JuCo23\n",
      "83/165: Processing ID = GaPt12\n",
      "84/165: Processing ID = SiCo30\n",
      "85/165: Processing ID = JuCo20\n",
      "86/165: Processing ID = GaCo11\n",
      "87/165: Processing ID = GaPt16\n",
      "88/165: Processing ID = SiCo21\n",
      "89/165: Processing ID = GaCo05\n",
      "90/165: Processing ID = SiCo13\n",
      "91/165: Processing ID = JuCo22\n",
      "92/165: Processing ID = SiCo19\n",
      "93/165: Processing ID = SiCo09\n",
      "94/165: Processing ID = GaPt21\n",
      "95/165: Processing ID = JuCo08\n",
      "96/165: Processing ID = JuPt22\n",
      "97/165: Processing ID = GaPt33\n",
      "98/165: Processing ID = GaCo04\n",
      "99/165: Processing ID = JuPt16\n",
      "100/165: Processing ID = SiPt12\n",
      "101/165: Processing ID = JuPt25\n",
      "102/165: Processing ID = GaPt17\n",
      "103/165: Processing ID = JuCo25\n",
      "104/165: Processing ID = SiPt04\n",
      "105/165: Processing ID = JuPt13\n",
      "106/165: Processing ID = SiCo15\n",
      "107/165: Processing ID = SiPt15\n",
      "108/165: Processing ID = GaPt30\n",
      "109/165: Processing ID = SiCo05\n",
      "110/165: Processing ID = SiCo20\n",
      "111/165: Processing ID = SiPt21\n",
      "112/165: Processing ID = JuPt18\n",
      "113/165: Processing ID = SiPt30\n",
      "114/165: Processing ID = SiCo17\n",
      "115/165: Processing ID = GaCo03\n",
      "116/165: Processing ID = GaPt25\n",
      "117/165: Processing ID = SiCo26\n",
      "118/165: Processing ID = SiPt40\n",
      "119/165: Processing ID = SiPt10\n",
      "120/165: Processing ID = SiCo25\n",
      "121/165: Processing ID = JuCo01\n",
      "122/165: Processing ID = JuPt12\n",
      "123/165: Processing ID = SiPt19\n",
      "124/165: Processing ID = SiPt02\n",
      "125/165: Processing ID = SiPt36\n",
      "126/165: Processing ID = SiPt27\n",
      "127/165: Processing ID = GaCo07\n",
      "128/165: Processing ID = SiPt23\n",
      "129/165: Processing ID = SiPt07\n",
      "130/165: Processing ID = GaPt07\n",
      "131/165: Processing ID = SiPt28\n",
      "132/165: Processing ID = SiPt32\n",
      "133/165: Processing ID = JuPt07\n",
      "134/165: Processing ID = JuPt19\n",
      "135/165: Processing ID = SiPt31\n",
      "136/165: Processing ID = GaPt05\n",
      "137/165: Processing ID = SiPt24\n",
      "138/165: Processing ID = GaCo14\n",
      "139/165: Processing ID = SiCo14\n",
      "140/165: Processing ID = JuCo26\n",
      "141/165: Processing ID = SiPt09\n",
      "142/165: Processing ID = SiCo29\n",
      "143/165: Processing ID = JuCo11\n",
      "144/165: Processing ID = JuCo07\n",
      "145/165: Processing ID = SiPt16\n",
      "146/165: Processing ID = SiPt08\n",
      "147/165: Processing ID = GaCo16\n",
      "148/165: Processing ID = SiPt25\n",
      "149/165: Processing ID = JuCo17\n",
      "150/165: Processing ID = JuPt02\n",
      "151/165: Processing ID = SiPt22\n",
      "152/165: Processing ID = JuPt27\n",
      "153/165: Processing ID = GaPt04\n",
      "154/165: Processing ID = SiPt35\n",
      "155/165: Processing ID = JuCo12\n",
      "156/165: Processing ID = GaPt03\n",
      "157/165: Processing ID = SiCo12\n",
      "158/165: Processing ID = SiPt05\n",
      "159/165: Processing ID = SiCo06\n",
      "160/165: Processing ID = SiCo18\n",
      "161/165: Processing ID = SiPt33\n",
      "162/165: Processing ID = GaPt06\n",
      "163/165: Processing ID = GaCo12\n",
      "164/165: Processing ID = JuCo14\n",
      "165/165: Processing ID = JuCo05\n",
      "-----------------END-----------------\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "sensors = [\n",
    "    (lambda x: x.L1 - x.R1, \"LR1\"),\n",
    "    (lambda x: x.L2 - x.R2, \"LR2\"),\n",
    "    (lambda x: x.L3 - x.R3, \"LR3\"),\n",
    "    (lambda x: x.L4 - x.R4, \"LR4\"),\n",
    "    (lambda x: x.L5 - x.R5, \"LR5\"),\n",
    "    (lambda x: x.L6 - x.R6, \"LR6\"),\n",
    "    (lambda x: x.L7 - x.R7, \"LR7\"),\n",
    "    (lambda x: x.L8 - x.R8, \"LR8\"),\n",
    "    ]\n",
    "\n",
    "i = 1\n",
    "if scenario4:\n",
    "    for id, value in records.items():\n",
    "        print(f'{i}/{len(records)}: Processing ID = {id}')\n",
    "        i = i + 1\n",
    "        parkinson = utils.getParkinsonStatus(patients, id)\n",
    "        hoehnYahr = utils.getHoehnYahrStatus(patients, id)\n",
    "        record = value['data1']\n",
    "\n",
    "        splits_list = [i for i in range(0, len(record), sample_number)]\n",
    "\n",
    "        utils.createDatabase(record, id, sensors, splits_list, sample_number, main_path, parkinson, widths, w)\n",
    "    print('-----------------END-----------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datasets created\n"
     ]
    }
   ],
   "source": [
    "if scenario4:\n",
    "    for wavelet in ['Ricker', 'Morlet']:\n",
    "        utils.createDatasets(f'{main_path}/{wavelet}')\n",
    "    print('Datasets created')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Uczenie sieci"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import LearningUtils\n",
    "import importlib\n",
    "import ModelTrainer\n",
    "from torchvision import models\n",
    "import logging\n",
    "import sys\n",
    "importlib.reload(ModelTrainer)\n",
    "importlib.reload(LearningUtils)\n",
    "\n",
    "\n",
    "if False:\n",
    "    for wavelet in ['Ricker', 'Morlet']:\n",
    "        print(f'Resnet for {wavelet}')\n",
    "        imgdir = f\"{main_path}/{wavelet}\"\n",
    "        # logger\n",
    "        logger = logging.getLogger()\n",
    "        logger.setLevel(logging.DEBUG)\n",
    "        fhandler = logging.FileHandler(f'{imgdir}/log.txt', mode='w')\n",
    "        consoleHandler = logging.StreamHandler(sys.stdout)\n",
    "        logger.addHandler(fhandler)\n",
    "        logger.addHandler(consoleHandler)\n",
    "\n",
    "        classes = LearningUtils.get_classes(imgdir)\n",
    "        train_data_loader, validation_data_loader, test_data_loader = LearningUtils.prepare_data(imgdir, 64)\n",
    "        model_trainer = ModelTrainer.ModelTrainer(classes, imgdir)\n",
    "        resnet = models.resnet18(weights=models.ResNet18_Weights.DEFAULT)\n",
    "        model = model_trainer.train_resnet(resnet, train_data_loader, validation_data_loader, num_epochs=num_epochs)\n",
    "        model.eval()\n",
    "        LearningUtils.predict_image(model, test_data_loader, classes)\n",
    "\n",
    "        logger.removeHandler(fhandler)\n",
    "        logger.removeHandler(consoleHandler)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.3 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "vscode": {
   "interpreter": {
    "hash": "9650cb4e16cdd4a8e8e2d128bf38d875813998db22a3c986335f89e0cb4d7bb2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
