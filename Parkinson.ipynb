{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Kaczmarek Kacper\n",
    "Jakiś wstęp potem\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "---\n",
    "# Procesowanie sygnału\n",
    "#### 1. Zaciągnięcie danych z bazy https://physionet.org/content/gaitpdb/1.0.0/\n",
    "#### 2. Zaczytanie danych\n",
    "#### 3. Przedstawienie danych\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Zaczytanie danych"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### Zaczytanie metadanych"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "patients = pd.read_csv('Data/demographics.txt', sep='\\\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### Zaczytanie danych o pacjentach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import utils\n",
    "\n",
    "records = utils.readData()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Prezentacja danych"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### Przykład zdrowego i chorego i rozkład sił na lewej i prawej stopie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import utils\n",
    "\n",
    "healthy_patient_id = \"GaCo16\"\n",
    "parkinson_patient_id = \"GaPt26\"\n",
    "sample_number = 240\n",
    "\n",
    "healthy_record = records[healthy_patient_id][\"data1\"]\n",
    "parkinson_record = records[parkinson_patient_id][\"data1\"]\n",
    "\n",
    "utils.createComparisonPlot(healthy_record, parkinson_record, sample_number)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### Każdy czujnik dla zdrowego i chorego"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import utils\n",
    "healthy_patient_id = \"GaCo16\"\n",
    "\n",
    "healthy_record = records[healthy_patient_id][\"data1\"]\n",
    "\n",
    "utils.createAllSensorPlot(healthy_record, 'healthy_all_sensors', sample_number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import utils\n",
    "parkinson_patient_id = \"GaPt26\"\n",
    "\n",
    "parkinson_record = records[parkinson_patient_id][\"data1\"]\n",
    "\n",
    "utils.createAllSensorPlot(parkinson_record, 'parkinson_all_sensors', sample_number)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### Wyliczenie najmniejszej porcji danych chodu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sample_len = float(\"inf\")\n",
    "for key, value in records.items():\n",
    "    record = value['data1']\n",
    "    sample_len = min(len(record.Time), sample_len)\n",
    "\n",
    "print(sample_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pokazanie zachowań kroków na podstawie czujnika prawej stopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "steps = {}\n",
    "minVal = 30\n",
    "for key, value in records.items():\n",
    "    record = value['data1']\n",
    "    idx = record.index[record.Force_Right < minVal].tolist()[0] + 1\n",
    "    start = record[idx:].index[record.Force_Right[idx:] > minVal].tolist()[0]\n",
    "    end = record[start:].index[record[start:].Force_Right < minVal].tolist()[0]\n",
    "    step = record.Force_Right[start:end+1].tolist()\n",
    "    steps[key] = [x / max(step) for x in step]\n",
    "\n",
    "parkinsons = []\n",
    "healthys = []\n",
    "for key in steps:\n",
    "    hoehnYahr = patients[patients['ID'] == key]['HoehnYahr'].values[0]\n",
    "    parkinsons.append(key) if hoehnYahr > 0 else healthys.append(key)\n",
    "    \n",
    "\n",
    "plt.figure()\n",
    "for key in parkinsons:\n",
    "    plt.plot(steps[key])\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "for key in healthys:\n",
    "    plt.plot(steps[key])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "steps = {}\n",
    "minVal = 50\n",
    "maxStep = float(\"-inf\")\n",
    "for key, value in records.items():\n",
    "    record = value['data1']\n",
    "    idx = record.index[record.Force_Right < minVal].tolist()[0] + 1\n",
    "    start = record[idx:].index[record.Force_Right[idx:] > minVal].tolist()[0]\n",
    "    end = record[start:].index[record[start:].Force_Right < minVal].tolist()[0]\n",
    "    step = record.Force_Right[start:end+1].tolist()\n",
    "    maxStep = max(maxStep, len(step))\n",
    "    steps[key] = [x / max(step) for x in step]\n",
    "print(maxStep)\n",
    "def rescale(arr, maxStep):\n",
    "    n = len(arr)\n",
    "    return np.interp(np.linspace(0, n, maxStep), np.arange(n), arr)\n",
    "parkinsons = []\n",
    "healthys = []\n",
    "for key in steps:\n",
    "    hoehnYahr = patients[patients['ID'] == key]['HoehnYahr'].values[0]\n",
    "    parkinsons.append(key) if hoehnYahr > 0 else healthys.append(key)\n",
    "    \n",
    "\n",
    "plt.figure()\n",
    "for key in parkinsons:\n",
    "    plt.plot(rescale(steps[key], maxStep))\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "for key in healthys:\n",
    "    plt.plot(rescale(steps[key], maxStep))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Porównanie podczas liczenia do 7 w dół"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "steps = {}\n",
    "minVal = 50\n",
    "maxStep = float(\"-inf\")\n",
    "for key, value in records.items():\n",
    "    if key.startswith('Ga') and 'data10' in value.keys():\n",
    "        record = value['data10']\n",
    "        idx = record.index[record.Force_Right < minVal].tolist()[0] + 1\n",
    "        start = record[idx:].index[record.Force_Right[idx:] > minVal].tolist()[0]\n",
    "        end = record[start:].index[record[start:].Force_Right < minVal].tolist()[0]\n",
    "        step = record.Force_Right[start:end+1].tolist()\n",
    "        maxStep = max(maxStep, len(step))\n",
    "        steps[key] = [x / max(step) for x in step]\n",
    "print(maxStep)\n",
    "def rescale(arr, maxStep):\n",
    "    n = len(arr)\n",
    "    return np.interp(np.linspace(0, n, maxStep), np.arange(n), arr)\n",
    "parkinsons = []\n",
    "healthys = []\n",
    "for key in steps:\n",
    "    hoehnYahr = patients[patients['ID'] == key]['HoehnYahr'].values[0]\n",
    "    parkinsons.append(key) if hoehnYahr > 0 else healthys.append(key)\n",
    "    \n",
    "\n",
    "plt.figure()\n",
    "for key in parkinsons:\n",
    "    plt.plot(rescale(steps[key], maxStep))\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "for key in healthys:\n",
    "    plt.plot(rescale(steps[key], maxStep))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### Prezentacja typów falek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from scipy import signal\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "points = 100\n",
    "a = 4\n",
    "w = 0\n",
    "\n",
    "plt.figure()\n",
    "vec_ricker = signal.ricker(points, a)\n",
    "plt.plot(vec_ricker)\n",
    "\n",
    "plt.savefig(\"plots/wavelet-type-ricker.pdf\", format=\"pdf\", bbox_inches=\"tight\")\n",
    "\n",
    "plt.figure()\n",
    "vec_morlet2 = signal.morlet2(points, a, w)\n",
    "plt.plot(vec_morlet2)\n",
    "\n",
    "plt.savefig(\"plots/wavelet-type-morlet.pdf\", format=\"pdf\", bbox_inches=\"tight\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### Wykresy transfomaty falkowej"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from scipy import signal\n",
    "import numpy as np\n",
    "\n",
    "healthy_patient_id = \"GaCo16\"\n",
    "parkinson_patient_id = \"GaPt26\"\n",
    "\n",
    "healthy_record = records[healthy_patient_id][\"data1\"]\n",
    "parkinson_record = records[parkinson_patient_id][\"data1\"]\n",
    "\n",
    "sample_number = 1000\n",
    "\n",
    "y_healthy = healthy_record.Force_Left.head(sample_number) - healthy_record.Force_Right.head(sample_number)\n",
    "y_healthy = y_healthy.abs()\n",
    "x_healthy = healthy_record.Time.head(sample_number)\n",
    "\n",
    "y_parkinson = parkinson_record.Force_Left.head(sample_number) - parkinson_record.Force_Right.head(sample_number)\n",
    "y_parkinson = y_parkinson.abs()\n",
    "x_parkinson = parkinson_record.Time.head(sample_number)\n",
    "\n",
    "width = 50\n",
    "widths = np.arange(1, width)\n",
    "cwtFunc = lambda: signal.cwt(y_healthy, signal.ricker, widths, dtype='float64')\n",
    "path = \"plots/healthy-wavelet\"\n",
    "utils.createWaveletPlot(x_healthy, cwtFunc, width, path, 'pdf')\n",
    "\n",
    "widths = np.arange(1, width)\n",
    "cwtFunc = lambda: signal.cwt(y_parkinson, signal.ricker, widths, dtype='float64')\n",
    "path = \"plots/parkinson-wavelet\"\n",
    "utils.createWaveletPlot(x_parkinson, cwtFunc, width, path, 'pdf')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Porównanie tranformaty falkowej morleta i rickera"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from scipy import signal\n",
    "import numpy as np\n",
    "\n",
    "healthy_patient_id = \"GaCo16\"\n",
    "parkinson_patient_id = \"GaPt26\"\n",
    "\n",
    "healthy_record = records[healthy_patient_id][\"data1\"]\n",
    "\n",
    "# sample_number = 4034\n",
    "sample_number = 1000\n",
    "\n",
    "y_healthy = healthy_record.Force_Left.head(sample_number)\n",
    "x_healthy = healthy_record.Time.head(sample_number)\n",
    "\n",
    "width = 50\n",
    "\n",
    "w = 0\n",
    "widths = np.arange(1, width)\n",
    "cwtFunc = lambda: signal.cwt(y_healthy, signal.morlet2, widths, dtype='float64', w=w)\n",
    "path = \"plots/healthy-morlet\"\n",
    "utils.createWaveletPlot(x_healthy, cwtFunc, width, path, 'pdf')\n",
    "\n",
    "widths = np.arange(1, width)\n",
    "cwtFunc = lambda: signal.cwt(y_healthy, signal.ricker, widths, dtype='float64')\n",
    "path = \"plots/healthy-ricker\"\n",
    "utils.createWaveletPlot(x_healthy, cwtFunc, width, path, 'pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Klasyfikacja"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "width = 50\n",
    "widths = np.arange(1, width)\n",
    "howManyInSample = 500\n",
    "w = 0.0\n",
    "num_epochs = 500"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scenariusz 1 - Pojedyncze czujniki"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scenario1 = False\n",
    "if scenario1:\n",
    "    main_path = f'Datasets/Binary/AllSensors'\n",
    "    utils.removeDatasetFolders(main_path)\n",
    "    for wavelet in ['Ricker', 'Morlet']:\n",
    "        utils.createDatasetFolders(f'{main_path}/{wavelet}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "sensors = [\n",
    "    (lambda x: x.L1, \"L1\"),\n",
    "    (lambda x: x.L2, \"L2\"),\n",
    "    (lambda x: x.L3, \"L3\"),\n",
    "    (lambda x: x.L4, \"L4\"),\n",
    "    (lambda x: x.L5, \"L5\"),\n",
    "    (lambda x: x.L6, \"L6\"),\n",
    "    (lambda x: x.L7, \"L7\"),\n",
    "    (lambda x: x.L8, \"L8\"),\n",
    "    # (lambda x: x.Force_Left, \"Force_Left\"),\n",
    "    (lambda x: x.R1, \"R1\"),\n",
    "    (lambda x: x.R2, \"R2\"),\n",
    "    (lambda x: x.R3, \"R3\"),\n",
    "    (lambda x: x.R4, \"R4\"),\n",
    "    (lambda x: x.R5, \"R5\"),\n",
    "    (lambda x: x.R6, \"R6\"),\n",
    "    (lambda x: x.R7, \"R7\"),\n",
    "    (lambda x: x.R8, \"R8\"),\n",
    "    # (lambda x: x.Force_Right, \"Force_Right\")\n",
    "    ]\n",
    "\n",
    "i = 1\n",
    "if scenario1:\n",
    "    for id, value in records.items():\n",
    "        print(f'{i}/{len(records)}: Processing ID = {id}')\n",
    "        i = i + 1\n",
    "        parkinson = utils.getParkinsonStatus(patients, id)\n",
    "        hoehnYahr = utils.getHoehnYahrStatus(patients, id)\n",
    "        record = value['data1']\n",
    "\n",
    "        splits_list = [i for i in range(0, len(record), howManyInSample)]\n",
    "        \n",
    "        utils.createDatabase(record, id, sensors, splits_list, howManyInSample, main_path, parkinson, widths, w)\n",
    "    print('-----------------END-----------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if scenario1:\n",
    "    for wavelet in ['Ricker', 'Morlet']:\n",
    "        utils.createDatasets(f'{main_path}/{wavelet}')\n",
    "    print('Datasets created')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### Uczenie sieci"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import LearningUtils\n",
    "import importlib\n",
    "import ModelTrainer\n",
    "from torchvision import models\n",
    "import logging\n",
    "import sys\n",
    "importlib.reload(ModelTrainer)\n",
    "importlib.reload(LearningUtils)\n",
    "\n",
    "\n",
    "if scenario1:\n",
    "    for wavelet in ['Ricker', 'Morlet']:\n",
    "        print(f'Resnet for {wavelet}')\n",
    "        imgdir = f\"{main_path}/{wavelet}\"\n",
    "        # logger\n",
    "        logger = logging.getLogger()\n",
    "        logger.setLevel(logging.DEBUG)\n",
    "        fhandler = logging.FileHandler(f'{imgdir}/log.txt', mode='w')\n",
    "        consoleHandler = logging.StreamHandler(sys.stdout)\n",
    "        logger.addHandler(fhandler)\n",
    "        logger.addHandler(consoleHandler)\n",
    "\n",
    "        classes = LearningUtils.get_classes(imgdir)\n",
    "        train_data_loader, validation_data_loader, test_data_loader = LearningUtils.prepare_data(imgdir, 128)\n",
    "        model_trainer = ModelTrainer.ModelTrainer(classes, imgdir)\n",
    "        resnet = models.resnet18(weights=models.ResNet18_Weights.DEFAULT)\n",
    "        model = model_trainer.train_resnet(resnet, train_data_loader, validation_data_loader, num_epochs=num_epochs)\n",
    "        model.eval()\n",
    "        LearningUtils.predict_image(model, test_data_loader, classes)\n",
    "\n",
    "        logger.removeHandler(fhandler)\n",
    "        logger.removeHandler(consoleHandler)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Scenariusz 2 - Tylko sumaryczne"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "scenario2 = False\n",
    "if scenario2:\n",
    "    main_path = f'Datasets/Binary/OnlySums'\n",
    "    utils.removeDatasetFolders(main_path)\n",
    "    for wavelet in ['Ricker', 'Morlet']:\n",
    "        utils.createDatasetFolders(f'{main_path}/{wavelet}')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "sensors = [\n",
    "    # (lambda x: x.L1, \"L1\"),\n",
    "    # (lambda x: x.L2, \"L2\"),\n",
    "    # (lambda x: x.L3, \"L3\"),\n",
    "    # (lambda x: x.L4, \"L4\"),\n",
    "    # (lambda x: x.L5, \"L5\"),\n",
    "    # (lambda x: x.L6, \"L6\"),\n",
    "    # (lambda x: x.L7, \"L7\"),\n",
    "    # (lambda x: x.L8, \"L8\"),\n",
    "    (lambda x: x.Force_Left, \"Force_Left\"),\n",
    "    # (lambda x: x.R1, \"R1\"),\n",
    "    # (lambda x: x.R2, \"R2\"),\n",
    "    # (lambda x: x.R3, \"R3\"),\n",
    "    # (lambda x: x.R4, \"R4\"),\n",
    "    # (lambda x: x.R5, \"R5\"),\n",
    "    # (lambda x: x.R6, \"R6\"),\n",
    "    # (lambda x: x.R7, \"R7\"),\n",
    "    # (lambda x: x.R8, \"R8\"),\n",
    "    (lambda x: x.Force_Right, \"Force_Right\")\n",
    "    ]\n",
    "\n",
    "i = 1\n",
    "if scenario2:\n",
    "    for id, value in records.items():\n",
    "        print(f'{i}/{len(records)}: Processing ID = {id}')\n",
    "        i = i + 1\n",
    "        parkinson = utils.getParkinsonStatus(patients, id)\n",
    "        hoehnYahr = utils.getHoehnYahrStatus(patients, id)\n",
    "        record = value['data1']\n",
    "\n",
    "        splits_list = [i for i in range(0, len(record), howManyInSample)]\n",
    "\n",
    "        utils.createDatabase(record, id, sensors, splits_list, howManyInSample, main_path, parkinson, widths, w)\n",
    "    print('-----------------END-----------------')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "if scenario2:\n",
    "    for wavelet in ['Ricker', 'Morlet']:\n",
    "        utils.createDatasets(f'{main_path}/{wavelet}')\n",
    "    print('Datasets created')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Uczenie sieci"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import LearningUtils\n",
    "import importlib\n",
    "import ModelTrainer\n",
    "from torchvision import models\n",
    "import logging\n",
    "import sys\n",
    "importlib.reload(ModelTrainer)\n",
    "importlib.reload(LearningUtils)\n",
    "\n",
    "\n",
    "if scenario2:\n",
    "    for wavelet in ['Morlet']:\n",
    "        print(f'Resnet for {wavelet}')\n",
    "        imgdir = f\"{main_path}/{wavelet}\"\n",
    "        # logger\n",
    "        logger = logging.getLogger()\n",
    "        logger.setLevel(logging.DEBUG)\n",
    "        fhandler = logging.FileHandler(f'{imgdir}/log.txt', mode='w')\n",
    "        consoleHandler = logging.StreamHandler(sys.stdout)\n",
    "        logger.addHandler(fhandler)\n",
    "        logger.addHandler(consoleHandler)\n",
    "\n",
    "        classes = LearningUtils.get_classes(imgdir)\n",
    "        train_data_loader, validation_data_loader, test_data_loader = LearningUtils.prepare_data(imgdir, 64)\n",
    "        model_trainer = ModelTrainer.ModelTrainer(classes, imgdir)\n",
    "        resnet = models.resnet18(weights=models.ResNet18_Weights.DEFAULT)\n",
    "        model = model_trainer.train_resnet(resnet, train_data_loader, validation_data_loader, num_epochs=num_epochs)\n",
    "        model.eval()\n",
    "        LearningUtils.predict_image(model, test_data_loader, classes)\n",
    "\n",
    "        logger.removeHandler(fhandler)\n",
    "        logger.removeHandler(consoleHandler)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Scenariusz 3 - Tylko różnica"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "scenario3 = True\n",
    "if scenario3:\n",
    "    main_path = f'Datasets/Binary/Diff'\n",
    "    utils.removeDatasetFolders(main_path)\n",
    "    for wavelet in ['Ricker', 'Morlet']:\n",
    "        utils.createDatasetFolders(f'{main_path}/{wavelet}')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "sensors = [\n",
    "    # (lambda x: x.L1, \"L1\"),\n",
    "    # (lambda x: x.L2, \"L2\"),\n",
    "    # (lambda x: x.L3, \"L3\"),\n",
    "    # (lambda x: x.L4, \"L4\"),\n",
    "    # (lambda x: x.L5, \"L5\"),\n",
    "    # (lambda x: x.L6, \"L6\"),\n",
    "    # (lambda x: x.L7, \"L7\"),\n",
    "    # (lambda x: x.L8, \"L8\"),\n",
    "    (lambda x: x.Force_Left - x.Force_Right, \"Diff\")\n",
    "    # (lambda x: x.R1, \"R1\"),\n",
    "    # (lambda x: x.R2, \"R2\"),\n",
    "    # (lambda x: x.R3, \"R3\"),\n",
    "    # (lambda x: x.R4, \"R4\"),\n",
    "    # (lambda x: x.R5, \"R5\"),\n",
    "    # (lambda x: x.R6, \"R6\"),\n",
    "    # (lambda x: x.R7, \"R7\"),\n",
    "    # (lambda x: x.R8, \"R8\"),\n",
    "    # (lambda x: x.Force_Right, \"Force_Right\")\n",
    "    ]\n",
    "\n",
    "i = 1\n",
    "if scenario3:\n",
    "    for id, value in records.items():\n",
    "        print(f'{i}/{len(records)}: Processing ID = {id}')\n",
    "        i = i + 1\n",
    "        parkinson = utils.getParkinsonStatus(patients, id)\n",
    "        hoehnYahr = utils.getHoehnYahrStatus(patients, id)\n",
    "        record = value['data1']\n",
    "\n",
    "        splits_list = [i for i in range(0, len(record), howManyInSample)]\n",
    "\n",
    "        utils.createDatabase(record, id, sensors, splits_list, howManyInSample, main_path, parkinson, widths, w)\n",
    "    print('-----------------END-----------------')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "if scenario3:\n",
    "    for wavelet in ['Ricker', 'Morlet']:\n",
    "        utils.createDatasets(f'{main_path}/{wavelet}')\n",
    "    print('Datasets created')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Uczenie sieci"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import LearningUtils\n",
    "import importlib\n",
    "import ModelTrainer\n",
    "from torchvision import models\n",
    "import logging\n",
    "import sys\n",
    "importlib.reload(ModelTrainer)\n",
    "importlib.reload(LearningUtils)\n",
    "\n",
    "\n",
    "if scenario3:\n",
    "    for wavelet in ['Morlet']:\n",
    "        print(f'Resnet for {wavelet}')\n",
    "        imgdir = f\"{main_path}/{wavelet}\"\n",
    "        # logger\n",
    "        logger = logging.getLogger()\n",
    "        logger.setLevel(logging.DEBUG)\n",
    "        fhandler = logging.FileHandler(f'{imgdir}/log.txt', mode='w')\n",
    "        consoleHandler = logging.StreamHandler(sys.stdout)\n",
    "        logger.addHandler(fhandler)\n",
    "        logger.addHandler(consoleHandler)\n",
    "\n",
    "        classes = LearningUtils.get_classes(imgdir)\n",
    "        train_data_loader, validation_data_loader, test_data_loader = LearningUtils.prepare_data(imgdir, 64)\n",
    "        model_trainer = ModelTrainer.ModelTrainer(classes, imgdir)\n",
    "        resnet = models.resnet18(weights=models.ResNet18_Weights.DEFAULT)\n",
    "        model = model_trainer.train_resnet(resnet, train_data_loader, validation_data_loader, num_epochs=num_epochs)\n",
    "        model.eval()\n",
    "        LearningUtils.predict_image(model, test_data_loader, classes)\n",
    "\n",
    "        logger.removeHandler(fhandler)\n",
    "        logger.removeHandler(consoleHandler)"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.3 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "vscode": {
   "interpreter": {
    "hash": "9650cb4e16cdd4a8e8e2d128bf38d875813998db22a3c986335f89e0cb4d7bb2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
